
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/4-profiling.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_examples_4-profiling.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_4-profiling.py:


Profiling your models
=====================

.. py:currentmodule:: metatomic.torch

Do you feel like your model is too slow? Do you want to make it faster? Instead of
guessing which part of the code is responsible for the slowdown, you should profile your
code to learn how much time is spent in each function and where to focus any
optimization efforts.

In this tutorial you'll learn how to profile your model using the PyTorch
profiler, how to read the output of the profiler, and how to add your own labels
for new functions/steps in your model's forward function.

.. GENERATED FROM PYTHON SOURCE LINES 16-35

.. code-block:: Python


    from typing import Dict, List, Optional

    import ase.build
    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from metatensor.torch import Labels, TensorBlock, TensorMap

    from metatomic.torch import (
        AtomisticModel,
        ModelCapabilities,
        ModelMetadata,
        ModelOutput,
        System,
    )
    from metatomic.torch.ase_calculator import MetatomicCalculator









.. GENERATED FROM PYTHON SOURCE LINES 36-39

When profiling your code, it is important to run the model on a representative system
to ensure you are actually exercising the behavior of your model at the right scale.
Here we'll use a relatively large system with many atoms.

.. GENERATED FROM PYTHON SOURCE LINES 40-46

.. code-block:: Python


    primitive = ase.build.bulk(name="C", crystalstructure="diamond", a=3.567)
    atoms = ase.build.make_supercell(primitive, 10 * np.eye(3))
    print(f"We have {len(atoms)} atoms in our system")






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    We have 2000 atoms in our system




.. GENERATED FROM PYTHON SOURCE LINES 47-55

We will use the same ``HarmonicModel`` as in the :ref:`previous tutorial
<atomistic-tutorial-md>` as our machine learning potential.

.. raw:: html

    <details>
    <summary>Click to see the definition of HarmonicModel</summary>


.. GENERATED FROM PYTHON SOURCE LINES 56-130

.. code-block:: Python



    class HarmonicModel(torch.nn.Module):
        def __init__(self, force_constant: float, equilibrium_positions: torch.Tensor):
            """Create an ``HarmonicModel``.

            :param force_constant: force constant, in ``energy unit / (length unit)^2``
            :param equilibrium_positions: torch tensor with shape ``n x 3``, containing the
                equilibrium positions of all atoms
            """
            super().__init__()
            assert force_constant > 0
            self.force_constant = force_constant
            self.equilibrium_positions = equilibrium_positions

        def forward(
            self,
            systems: List[System],
            outputs: Dict[str, ModelOutput],
            selected_atoms: Optional[Labels],
        ) -> Dict[str, TensorMap]:
            if list(outputs.keys()) != ["energy"]:
                raise ValueError(
                    "this model can only compute 'energy', but `outputs` contains other "
                    f"keys: {', '.join(outputs.keys())}"
                )

            # we don't want to worry about selected_atoms yet
            if selected_atoms is not None:
                raise NotImplementedError("selected_atoms is not implemented")

            if outputs["energy"].per_atom:
                raise NotImplementedError("per atom energy is not implemented")

            # compute the energy for each system by adding together the energy for each atom
            energy = torch.zeros((len(systems), 1), dtype=systems[0].positions.dtype)
            for i, system in enumerate(systems):
                assert len(system) == self.equilibrium_positions.shape[0]
                r0 = self.equilibrium_positions
                energy[i] += torch.sum(self.force_constant * (system.positions - r0) ** 2)

            # add metadata to the output
            block = TensorBlock(
                values=energy,
                samples=Labels("system", torch.arange(len(systems)).reshape(-1, 1)),
                components=[],
                properties=Labels("energy", torch.tensor([[0]])),
            )
            return {
                "energy": TensorMap(keys=Labels("_", torch.tensor([[0]])), blocks=[block])
            }


    model = HarmonicModel(
        force_constant=3.14159265358979323846,
        equilibrium_positions=torch.tensor(atoms.positions),
    )

    capabilities = ModelCapabilities(
        outputs={
            "energy": ModelOutput(quantity="energy", unit="eV", per_atom=False),
        },
        atomic_types=[6],
        interaction_range=0.0,
        length_unit="Angstrom",
        supported_devices=["cpu"],
        dtype="float32",
    )

    metadata = ModelMetadata()
    wrapper = AtomisticModel(model.eval(), metadata, capabilities)

    wrapper.export("exported-model.pt")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/metatomic/metatomic/python/examples/4-profiling.py:128: DeprecationWarning: `export()` is deprecated, use `save()` instead
      wrapper.export("exported-model.pt")




.. GENERATED FROM PYTHON SOURCE LINES 131-135

.. raw:: html

    </details>


.. GENERATED FROM PYTHON SOURCE LINES 138-140

If you are trying to profile your own model, you can start here and create
``MetatomicCalculator`` with your own model.

.. GENERATED FROM PYTHON SOURCE LINES 143-148

Profiling energy calculation
----------------------------

We will start with an energy-only calculator, which can be enabled with
``do_gradients_with_energy=False``.

.. GENERATED FROM PYTHON SOURCE LINES 149-152

.. code-block:: Python


    atoms.calc = MetatomicCalculator("exported-model.pt", do_gradients_with_energy=False)








.. GENERATED FROM PYTHON SOURCE LINES 153-155

Before trying to profile the code, it is a good idea to run it a couple of times to
allow torch to warmup internally.

.. GENERATED FROM PYTHON SOURCE LINES 156-162

.. code-block:: Python


    for _ in range(10):
        # force the model to re-run everytime, otherwise ASE caches calculation results
        atoms.rattle(1e-6)
        atoms.get_potential_energy()








.. GENERATED FROM PYTHON SOURCE LINES 163-165

Now we can run code using :py:func:`torch.profiler.profile` to collect statistic on
how long each function takes to run.

.. GENERATED FROM PYTHON SOURCE LINES 166-173

.. code-block:: Python


    atoms.rattle(1e-6)
    with torch.profiler.profile() as energy_profiler:
        atoms.get_potential_energy()

    print(energy_profiler.key_averages().table(sort_by="self_cpu_time_total", row_limit=10))





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                          Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  
    ------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
           MetatomicCalculator::prepare_inputs        22.46%     337.190us        32.46%     487.449us     487.449us             1  
                                Model::forward         9.36%     140.621us        23.68%     355.522us     355.522us             1  
            AtomisticModel::check_atomic_types         6.95%     104.326us        11.74%     176.339us     176.339us             1  
          AtomisticModel::convert_units_output         6.91%     103.713us         7.07%     106.218us     106.218us             1  
                                       forward         6.01%      90.300us        14.31%     214.901us     214.901us             1  
             MetatomicCalculator::sum_energies         5.41%      81.212us         5.41%      81.212us      81.212us             1  
           AtomisticModel::convert_units_input         4.51%      67.647us         4.69%      70.422us      70.422us             1  
        MetatomicCalculator::compute_neighbors         4.28%      64.310us         8.03%     120.595us     120.595us             1  
          MetatomicCalculator::convert_outputs         3.89%      58.348us         5.02%      75.400us      75.400us             1  
                        aten::_index_put_impl_         2.52%      37.881us         4.53%      67.987us      67.987us             1  
    ------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
    Self CPU time total: 1.502ms





.. GENERATED FROM PYTHON SOURCE LINES 174-199

There are a couple of interesting things to see here. First the total runtime of the
code is shown in the bottom; and then the most costly functions are visible on top,
one line per function. For each function, ``Self CPU`` refers to the time spent in
this function **excluding** any called functions; and ``CPU total`` refers to the time
spent in this function, **including** called functions.

For more options to record operations and display outputs, please refer to the
`official documentation for PyTorch profiler
<https://pytorch.org/docs/stable/profiler.html>`_.

Here, ``Model::forward`` indicates the time taken by your model's ``forward()``.
Anything starting with ``aten::`` comes from operations on torch tensors, typically
with the same function name as the corresponding torch functions (e.g.
``aten::arange`` is :py:func:`torch.arange`). We can also see some internal functions
from metatomic, with the name staring with ``AtomisticModel::`` for
:py:class:`AtomisticModel`; and ``MetatomicCalculator::`` for
:py:class:`ase_calculator.MetatomicCalculator`.

If you want to see more details on the internal steps taken by your model, you
can add :py:func:`torch.profiler.record_function`
(https://pytorch.org/docs/stable/generated/torch.autograd.profiler.record_function.html)
inside your model code to give names to different steps in the calculation.
This is how we internally set names such as ``Model::forward`` or
``MetatomicCalculator::prepare_inputs`` above.


.. GENERATED FROM PYTHON SOURCE LINES 202-208

Profiling forces calculation
----------------------------

Let us now do the same, but while also computing the forces for this system.
This mean we should now see some time spent in the ``backward()`` function, on
top of everything else.

.. GENERATED FROM PYTHON SOURCE LINES 209-224

.. code-block:: Python


    atoms.calc = MetatomicCalculator("exported-model.pt")

    # warmup
    for _ in range(10):
        atoms.rattle(1e-6)
        atoms.get_forces()

    atoms.rattle(1e-6)
    with torch.profiler.profile() as forces_profiler:
        atoms.get_forces()

    print(forces_profiler.key_averages().table(sort_by="self_cpu_time_total", row_limit=10))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  
    -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
                        MetatomicCalculator::prepare_inputs        12.70%     194.345us        19.19%     293.688us     293.688us             1  
                       MetatomicCalculator::convert_outputs         9.65%     147.737us        13.00%     198.991us     198.991us             1  
                          MetatomicCalculator::run_backward         9.02%     137.948us        21.11%     322.982us     322.982us             1  
                                             Model::forward         8.47%     129.562us        18.15%     277.708us     277.708us             1  
                       AtomisticModel::convert_units_output         4.98%      76.161us         5.08%      77.775us      77.775us             1  
                         AtomisticModel::check_atomic_types         4.89%      74.862us         8.40%     128.530us     128.530us             1  
                                                   aten::mm         4.23%      64.750us         4.28%      65.491us      16.373us             4  
                        AtomisticModel::convert_units_input         3.99%      61.083us         4.13%      63.137us      63.137us             1  
                          MetatomicCalculator::sum_energies         3.99%      60.994us         3.99%      60.994us      60.994us             1  
                                                    forward         3.80%      58.126us         9.68%     148.146us     148.146us             1  
    -------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  
    Self CPU time total: 1.530ms





.. GENERATED FROM PYTHON SOURCE LINES 225-226

Let's visualize this data in another way:

.. GENERATED FROM PYTHON SOURCE LINES 227-251

.. code-block:: Python


    events = forces_profiler.key_averages()
    events = sorted(events, key=lambda u: u.self_cpu_time_total, reverse=True)
    total_cpu_time = sum(map(lambda u: u.self_cpu_time_total, events))

    bottom = 0.0
    for event in events:
        self_time = event.self_cpu_time_total
        name = event.key
        if len(name) > 30:
            name = name[:12] + "[...]" + name[-12:]

        if self_time > 0.03 * total_cpu_time:
            plt.bar(0, self_time, bottom=bottom, label=name)
            bottom += self_time
        else:
            plt.bar(0, total_cpu_time - bottom, bottom=bottom, label="others")
            break

    plt.legend()
    plt.xticks([])
    plt.xlim(0, 1)
    plt.ylabel("self time / Âµs")
    plt.show()



.. image-sg:: /examples/images/sphx_glr_4-profiling_001.png
   :alt: 4 profiling
   :srcset: /examples/images/sphx_glr_4-profiling_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 1.242 seconds)


.. _sphx_glr_download_examples_4-profiling.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 4-profiling.ipynb <4-profiling.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 4-profiling.py <4-profiling.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: 4-profiling.zip <4-profiling.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
