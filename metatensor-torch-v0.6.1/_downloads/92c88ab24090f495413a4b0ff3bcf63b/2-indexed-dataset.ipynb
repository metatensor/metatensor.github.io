{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Using IndexedDataset\n\n.. py:currentmodule:: metatensor.torch.learn.data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport torch\n\nfrom metatensor.learn.data import DataLoader, Dataset, IndexedDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review of the standard Dataset\n\nThe previous tutorial, `learn-tutorial-dataset-dataloader`, showed how to define\na :py:class:`Dataset` able to handle both torch tensor and metatensor TensorMap. We\nsaw that in-memory, on-disk, or mixed in-memory/on-disk datasets can be defined.\nDataLoaders are then defined on top of these Dataset objects.\n\nIn all cases, however, each data sample is accessed by a numeric integer index, which\nranges from 0 to ``len(dataset) - 1``. Let's use a simple example to review this.\n\nAgain let's define some dummy data as before. Our x data as a list of random tensors,\nand our y data as a list of integers that enumerate the samples.\n\nFor the purposes of this tutorial, we will only focus on an in-memory dataset, though\nthe same principles apply to on-disk and mixed datasets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples = 5\nx_data = [torch.randn(3) for _ in range(n_samples)]\ny_data = [i for i in range(n_samples)]\n\ndataset = Dataset(x=x_data, y=y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A sample is accessed by its numeric index. As the length of the lists passed as kwargs\nis 5, both for ``x`` and ``y``, the valid indices are [0, 1, 2, 3, 4].\n\nLet's retrieve the 4th sample (index 3) and print it. The value of the \"y\" data field\nshould be 3.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What if we wanted to access samples by something other than an integer index part of a\ncontinuous range?\n\nFor instance, what if we wanted to access samples by:\n   1. a string id, or other arbitrary hashable object?\n   2. an integer index that is not defined inside a continuous range?\n\nIn these cases, we can use an IndexedDataset instead.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IndexedDataset\n\nFirst let's define a Dataset where the samples are indexed by arbitrary unique\nindexes, such as strings, integers, and tuples.\n\nSuppose the unique indexes for our 5 samples are:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_id = [\n    \"cat\",\n    4,\n    (\"small\", \"cow\"),\n    \"dog\",\n    0,\n]\n\n# Build an IndexedDataset, specifying the unique sample indexes with ``sample_id``\ndataset = IndexedDataset(\n    x=x_data,\n    y=y_data,\n    sample_id=sample_id,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, when we access the dataset, we can access samples by their unique sample index\nusing the ``get_sample`` method. This method takes a single argument, the sample\nindex, and returns the corresponding sample.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset.get_sample(\"dog\"))\nprint(dataset.get_sample(4))\nprint(dataset.get_sample((\"small\", \"cow\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that using ``__getitem__``, i.e. ``dataset[4]``, will return the sample passed to\nthe constructor at position 5. In this case, the sample indexes map to the numeric\nindices as follows:\n\n0. ``\"cat\"``\n1. ``4``\n2. ``(\"small\", \"cow\")``\n3. ``\"dog\"``\n4. ``0``\n\nThus, accessing the unique sample index ``\"cat\"`` can be done equivalently with\neither of:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(dataset[0])\nprint(dataset.get_sample(\"cat\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that the named tuple returned in both cases contains the unique sample index as\nthe ``sample_id`` field, which precedes all other data fields. This is in contrast to\nthe standard Dataset, which only returns the passed data fields and not the index.\n\nA :py:class:`DataLoader` can be constructed on top of an :py:class:`IndexedDataset`\nin the same way as a :py:class:`Dataset`. Batches are accessed by iterating over the\n:py:class:`DataLoader`, though this time the ``Batch`` named tuple returned by the\ndata loader will contain the unique sample indexes ``sample_id`` as the first field.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2)\n\n# Iterate over batches\nfor batch in dataloader:\n    print(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before, we can create separate variables in the iteration pattern\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for ids, x, y in dataloader:\n    print(ids, x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## On-disk :py:class:`IndexedDataset` with arbitrary sample indexes\n\nWhen defining an :py:class:`IndexedDataset` with data fields on-disk, i.e. to be\nloaded lazily, the sample indexes passed as the ``sample_id`` kwarg to the\nconstructor are used as the arguments to the load function.\n\nTo demonstrate this, as we did in the previous tutorial, let's save the ``x`` data to\ndisk and build a mixed in-memory/on-disk :py:class:`IndexedDataset`.\n\nFor instance, the below code will save sone x data for the sample ``\"dog\"`` at\nrelative path ``\"data/x_dog.pt\"``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a directory to save the dummy x data to disk\nos.makedirs(\"data\", exist_ok=True)\n\nfor i, x in zip(sample_id, x_data):\n    torch.save(x, f\"data/x_{i}.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now define a load function to load data from disk. This should take the unique\nsample index as a single argument, and return the corresponding data in memory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def load_x(sample_id):\n    \"\"\"\n    Loads the x data for the sample indexed by `sample_id` from disk and\n    returns the object in memory\n    \"\"\"\n    print(f\"loading x for sample {sample_id}\")\n    return torch.load(f\"data/x_{sample_id}.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now when we define an IndexedDataset, the 'x' data field can be passed as a\ncallable.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mixed_dataset = IndexedDataset(x=load_x, y=y_data, sample_id=sample_id)\nprint(mixed_dataset.get_sample(\"dog\"))\nprint(mixed_dataset.get_sample((\"small\", \"cow\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using an IndexedDataset: subset integer ranges\n\nOne could also define an IndexedDataset where the samples indices are integers forming\na possibly shuffled and non-continuous subset of a larger continuous range of numeric\nindices.\n\nFor instance, imagine we have a global Dataset of 1000 samples, with indices [0, ...,\n999], but only want to build a dataset for samples with indices [4, 7, 200, 5, 999],\nin that order. We can pass these indices kwarg ``sample_id``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Build an IndexedDataset, specifying the subset sample indexes in a specific order\nsample_id = [4, 7, 200, 5, 999]\ndataset = IndexedDataset(x=x_data, y=y_data, sample_id=sample_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, when we access the dataset, we can access samples by their unique sample index\nusing the `get_sample` method. This method takes a single argument, the sample index,\nand returns the corresponding sample.\n\nAgain, the numeric index can be used equivalently to access the sample, and again note\nthat the ``Sample`` named tuple includes the ``sample_id`` field.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# These return the same sample\nprint(dataset.get_sample(5))\nprint(dataset[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally, the DataLoader behaves as expected:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2)\n\nfor batch in dataloader:\n    print(batch)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}