{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# First steps with metatensor\n\n.. |CO2| replace:: CO\\ :sub:`2`\n\nThis tutorial explores how data is stored inside metatensor's ``TensorMap``, and how to\naccess the associated metadata. This is a companion to the `core classes overview\n<core-classes-overview>` page of this documentation, presenting the same concepts with\ncode examples.\n\nTo this end, we will need some data in metatensor format, which for the sake of\nsimplicity will be loaded from a file. The code used to generate this file can be found\nbelow:\n\n.. details:: Show the code used to generate the :download:`spherical-expansion.mts`\n             file, or use the link to download it\n\n    ..\n\n        The data was generated with `featomic`_, a package to compute atomistic\n        representations for machine learning applications.\n\n\n        .. literalinclude:: spherical-expansion.py.example\n            :language: python\n\nThe :py:class:`TensorMap` stored in the file contains a machine learning representation\n(the spherical expansion) of all the atoms in a |CO2| molecule. You don't need to know\nanything the spherical expansion to follow this tutorial!\n\n.. py:currentmodule:: metatensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ase\nimport ase.visualize.plot\nimport matplotlib.pyplot as plt\n\nimport metatensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For reference, we are working with a representation of this |CO2| molecule:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "co2 = ase.Atoms(\n    \"CO2\",\n    positions=[(0, 0, 0), (-0.2, -0.65, 0.94), (0.2, 0.65, -0.94)],\n)\n\n\nfig, ax = plt.subplots(figsize=(3, 3))\nase.visualize.plot.plot_atoms(co2, ax)\nax.set_axis_off()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The main entry point: ``TensorMap``\n\nWe'll start by loading our data with :py:func:`metatensor.load`. The ``tensor``\nreturned by this function is a :py:class:`TensorMap`, the core class of metatensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tensor = metatensor.load(\"spherical-expansion.mts\")\nprint(type(tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking at the tensor tells us that it is composed of 12 blocks, each associated with\na key:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that here, the keys of the :py:class:`TensorMap` have four named\n*dimensions*. Two of these are used to describe the behavior of the data under spatial\ntransformations (rotations and inversions in the O3 group):\n\n- ``o3_lambda``, indicating the character of o3 irreducible representation this block\n  is following. In general, a block with ``o3_lambda=3`` will transform under\n  rotations like a ``l=3`` spherical harmonics.\n- ``o3_sigma``, which describe the behavior of the data under inversion symmetry. Here\n  all blocks have ``o3_sigma=1``, meaning we only have data with the usual inversion\n  symmetry (``o3_sigma=-1`` would be used for pseudo-tensors);\n\nAnd the other two are related to the composition of the system:\n\n- ``center_type`` represents the atomic type of the central atom in consideration. For\n  |CO2|, we have both carbons (type 6) and oxygens (type 8);\n- ``neighbor_type`` represents the atomic type of the neighbor atoms considered by the\n  machine learning representation, in this case it takes the values 6 and 8 as well.\n\n\nThese keys can be accessed with :py:attr:`TensorMap.keys`, and they are an instance of\nthe :py:class:`Labels` class:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "keys = tensor.keys\nprint(type(keys))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ``Labels`` to store metadata\n\nOne of the `main goals of metatensor <metatensor-goal-exchange>` is to be able to\nstore both data and metadata together. We've just encountered the first example of\nthis metadata as the :py:class:`TensorMap` keys! In general, most metadata will be\nstored in the :py:class:`Labels` class. Let's explore this class a bit.\n\nAs already mentioned, :py:class:`Labels` can have multiple dimensions, and each\ndimension has a name. We can look at all the dimension names simultaneously with\n:py:func:`Labels.names`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(keys.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":py:class:`Labels` then contains multiple entries, each entry being described by a set\nof integer values, one for each dimension of the labels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(keys.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can access all the values taken by a given dimension/column in the labels with\n:py:func:`Labels.column` or by indexing with a string:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(keys[\"o3_lambda\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(keys.column(\"center_type\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also access individual entries in the labels by iterating over them or indexing\nwith an integer:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Entries with o3_lambda=2:\")\nfor entry in keys:\n    if entry[\"o3_lambda\"] == 2:\n        print(\"    \", entry)\n\nprint(\"\\nEntry at index 3:\")\nprint(\"    \", keys[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ``TensorBlock`` to store the data\n\nEach entry in the :py:attr:`TensorMap.keys` is associated with a\n:py:class:`TensorBlock`, which contains the actual data and some additional metadata.\nWe can extract the block from a key by indexing our :py:class:`TensorMap`, or with the\n:py:func:`TensorMap.block`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# this is equivalent to `block = tensor[tensor.keys[0]]`\nblock = tensor[0]\n\nblock = tensor.block(o3_lambda=1, center_type=8, neighbor_type=6)\n\nprint(block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each block contains some data, stored inside the :py:attr:`TensorBlock.values`. Here,\nthe values contains the different coefficients of the spherical expansion, i.e. our\natomistic machine learning representation.\n\nThe problem with this array is that we do not know what the different numbers\ncorrespond to: different libraries might be using different convention and storage\norder, and one has to read documentation carefully if they want to use this kind of\ndata. Metatensor helps by making this data self-describing; by attaching metadata to\neach element of the array indicating what exactly we are working with.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(block.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The metadata is attached to the different array axes, and stored in\n:py:class:`Labels`. The array must have at least two axes but can have more if\nrequired. Here, we have three:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(block.values.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The **first** dimension of the ``values`` array is described by the\n:py:attr:`TensorBlock.samples` labels, and correspond to **what** is being described.\nThis follows the usual convention in machine learning, using the different rows of the\narray to store separate samples/observations.\n\nHere, since we are working with a per-atom representation, the samples contain the\nindex of the structure and atomic center in this structure. Since we are looking at a\nblock for ``center_type=8``, we have two samples, one for each oxygen atom in our\nsingle |CO2| molecule.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(block.samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The **last** dimension of the ``values`` array is described by the\n:py:attr:`TensorBlock.properties` labels, and correspond to **how** we are\ndescribing our subject. Here, we are using a radial basis, indexed by an integer\n``n``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(repr(block.properties))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, each **intermediate** dimension of the ``values`` array is described by one\nset of :py:attr:`TensorBlock.components` labels. These dimensions correspond to one or\nmore *vectorial components* in the data. Here the only component corresponds to the\ndifferent $m$ number in spherical harmonics $Y_l^m$, going from -1 to 1\nsince we are looking at the block for ``o3_lambda = 1``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(block.components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All this metadata allow us to know exactly what each entry in the ``values``\ncorresponds to. For example, we can see that the value at position ``(1, 0, 3)``\ncorresponds to:\n\n- the center at index 2 inside the structure at index 0;\n- the ``m=-1`` part of the spherical harmonics;\n- the coefficients on the ``n=3`` radial basis function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"value =\", block.values[1, 0, 3])\nprint(\"sample =\", block.samples[1])\nprint(\"component =\", block.components[0][0])\nprint(\"property =\", block.properties[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Wrapping it up\n\n.. figure:: /../static/images/TensorMap.*\n    :width: 400px\n    :align: center\n\n    Illustration of the structure of a :py:class:`TensorMap`, with multiple keys and\n    blocks.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To summarize this tutorial, we saw that a :py:class:`TensorMap` contains multiple\n:py:class:`TensorBlock`, each associated with a key. The key describes the block, and\nwhat kind of data will be found inside.\n\nThe blocks contains the actual data, and multiple set of metadata, one for each axis\nof the data array.\n\n- The rows are described by ``samples`` labels, which describe **what** is being\n  stored;\n- the (generalized) columns are described by ``properties``, which describe **how**\n  the data is being represented;\n- Additional axes of the array correspond to vectorial ``components`` in the data.\n\nAll the metadata is stored inside :py:class:`Labels`, where each entry is described by\nthe integer values is takes along some named dimensions.\n\nFor a more visual approach to this data organization, you can also read the `core\nclasses overview <core-classes-overview>`.\n\nWe have learned how metatensor organizes its data, and what makes it a \"self\ndescribing data format\". In the `next tutorial <core-tutorial-sparsity>`, we will\nexplore what makes metatensor :py:class:`TensorMap` a \"sparse data format\".\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}