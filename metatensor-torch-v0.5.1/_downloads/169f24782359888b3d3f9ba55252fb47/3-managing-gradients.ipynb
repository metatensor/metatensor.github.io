{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Managing gradients\n\nAnother big difference between metatensor and other more generic data storage formats is\nits ability to store and manipulate one or more gradients of the data together with the\ndata itself. In this tutorial, we will see how and where gradients are stored, and what\none can do with them.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Metatensor supports multiple ways of managing gradients: explicit forward gradients,\n    presented in this tutorial; and implicit backward mode gradients (only when the data\n    is stored in :py:class:`torch.Tensor`). Both can be mixed as well, to compute\n    backward mode gradients of explicit forward mode gradients when training a model\n    with gradient data (forces and virial).\n\n    In general, the explicit forward gradients presented here are mainly relevant to you\n    if you are working within the numpy ecosystem; and the implicit backward gradients\n    are more interesting if you are working in the PyTorch ecosystem.\n\n    .. TODO add tutorial explaining the difference in more details and link to it here</p></div>\n\nThe code used to generate :download:`spherical-expansion.npz` is in `the first\ntutorial <core-tutorial-first-steps>`, and the code for :download:`radial-spectrum.npz`\nis shown `in the second <core-tutorial-sparsity>`. Notice how in both cases, the\ndata was computed with ``gradients=[\"positions\"]``, meaning the gradients with respect\nto atomic positions are included.\n\n.. py:currentmodule:: metatensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import metatensor\nfrom metatensor import TensorBlock, TensorMap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Amazing gradients and where to find them\n\nIn the first `tutorial <core-tutorial-first-steps>`, we have seen how metatensor\nstores data and metadata together inside :py:class:`TensorBlock`; and groups multiple\nblocks to form a full :py:class:`TensorMap`. To refresh our memory, let's load some\ndata (the radial spectrum from the `sparsity tutorial <core-tutorial-sparsity>`).\nIt is a tensor map with two dimensions for the keys; and 5 blocks:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "radial_spectrum = metatensor.load(\"radial-spectrum.npz\")\nprint(radial_spectrum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at one of the block, we can see that is contains gradients with respect to\n``\"positions\"``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "block = radial_spectrum.block(center_type=7, neighbor_type=7)\nprint(block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gradients are stored inside normal :py:class:`TensorBlock`, with their own set of\nmetadata in the samples, components and properties dimensions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gradient = block.gradient(\"positions\")\nprint(gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The samples are different from the values blocks (the block to which this gradient it\nattached to): there is a first ``\"sample\"`` dimension, followed by a pair of indices\n``(structure, atom)``.\n\nThe ``\"sample\"`` dimension is always present in gradients, and indicate which of the\nsamples in the values block we are taking the gradient of. Here, the first row of the\ngradients will contain a gradient of the first sample in the values; with respect to\nthe position of atom 4; while the last row of the gradients contains a gradient of the\nsecond row of the values with respect to the position of atom 5.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(gradient.samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Re-using the notation from the previous tutorial, the values contain $\\rho_i$,\nfor a given atomic center $i$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(block.samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look a the samples for the values, we can express the four samples in this\ngradient block as\n\n- $\\nabla_4 \\rho_4$: gradient of the representation of atom 4 with respect to\n  the position of atom 4;\n- $\\nabla_5 \\rho_4$: gradient of the representation of atom 4 with respect to\n  the position of atom 5;\n- $\\nabla_4 \\rho_5$: gradient of the representation of atom 5 with respect to\n  the position of atom 4;\n- $\\nabla_5 \\rho_5$: gradient of the representation of atom 5 with respect to\n  the position of atom 5.\n\nYou'll realize that some of the combinations of atoms are missing here: there is no\ngradient of $\\rho_4$ with respect to the positions of atom 0, 1, 2, *etc.* This\nis another instance of the data sparsity that metatensor enable: only the non-zero\ngradients are actually stored in memory.\n\n.. figure:: /../static/images/TensorBlock-Gradients.*\n    :width: 400px\n    :align: center\n\n    Visual illustration of the gradients, and how multiple gradient row/gradient\n    samples can correspond to the same row/sample in the values.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The gradient block can also differ from the values block in the components: here the\nvalues have no components, but the gradient have one, representing the x/y/z cartesian\ncoordinate direction of the gradient with respect to positions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(gradient.components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, the gradient properties are guaranteed to be the same as the values\nproperties.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(block.properties == gradient.properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The gradient block also contains the data for the gradient, in the ``values``\nattribute. Here the gradients are zeros everywhere except in the x direction because\nin the original input, the N\\ :sub:`2` molecule was oriented along the x axis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(gradient.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What if the values have components?\n\nWe have seen that the gradient samples are related to the values samples with the\n``sample`` dimension; and that the gradient are allowed to have custom ``components``.\nYou might be wondering what happen if the values already have some components!\n\nLet's load such an example, the spherical expansion from the `first steps\ntutorial <core-tutorial-first-steps>`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spherical_expansion = metatensor.load(\"spherical-expansion.npz\")\nprint(spherical_expansion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the :py:class:`TensorMap` above, the value blocks already have a set of components\ncorresponding to the $m$ index of spherical harmonics:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "block = spherical_expansion.block(2)\nprint(block.components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at the gradients with respect to positions, we see that they contain two\nsets of components: the same ``xyz`` component as the radial spectrum example\nearlier; and the same ``o3_mu`` as the values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gradient = block.gradient(\"positions\")\nprint(gradient)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"first set of components:\", gradient.components[0])\nprint(\"second set of components:\", gradient.components[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In general, the gradient blocks are allowed to have additional components when\ncompared to the values, but these extra components must come first, and are followed\nby the same set of components as the values.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using gradients in calculations\n\nNow that we know about gradient storage in metatensor, we should try to compute a new\nset of values and their corresponding gradients.\n\nLet's compute the square of the radial spectrum, $h(r) = \\rho^2(r)$, and the\ncorresponding gradients with respect to atomic positions. The chain rules tells us\nthat the gradient should be\n\n\\begin{align}\\nabla h(r) = 2\\ \\rho(r) * \\nabla \\rho(r)\\end{align}\n\nSince the calculation can happen block by block, let's define a function to compute a\nnew $h(r)$ block:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_square(block: TensorBlock) -> TensorBlock:\n    # compute the new values\n    new_values = block.values**2\n\n    # store the new values in a block\n    new_block = TensorBlock(\n        values=new_values,\n        samples=block.samples,\n        components=block.components,\n        properties=block.properties,\n    )\n\n    # compute the new gradient\n    gradient = block.gradient(\"positions\")\n\n    # `block.values[gradient.samples[\"sample\"]]` gives us an array with a shape\n    # compatible with `gradient.values`; using the right row in the values to compute\n    # the a given row of the gradients. ``None`` creates an additional dimension to\n    # match the components of the gradients.\n    broadcasted_values = block.values[gradient.samples[\"sample\"], None, :]\n    new_gradient_values = 2.0 * broadcasted_values * gradient.values\n\n    new_gradient = TensorBlock(\n        values=new_gradient_values,\n        samples=gradient.samples,\n        components=gradient.components,\n        properties=gradient.properties,\n    )\n\n    # store the gradient in the new block\n    new_block.add_gradient(\"positions\", new_gradient)\n\n    return new_block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One issue when applying the equation above blindly is that ``block.values`` (i.e.\n$\\rho(r)$) and ``gradient.values`` (i.e. $\\nabla \\rho(r)$) have different\nshape. Fortunately, we already know how to match them: ``gradient.samples[\"sample\"]``\ncontains the indices of ``block.values`` matching each row of ``gradient.values``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gradient = radial_spectrum.block(2).gradient(\"positions\")\nprint(gradient.samples[\"sample\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now apply this function on all the blocks, and reconstruct a new\n:py:class:`TensorMap`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "blocks = [compute_square(block) for block in radial_spectrum.blocks()]\nsquared = TensorMap(keys=radial_spectrum.keys, blocks=blocks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``squares`` has the same shape and sparsity pattern as ``radial_spectrum``, but\ncontains different values:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(squared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rs_block = radial_spectrum.block(2)\nsquared_block = squared.block(2)\n\nprint(\"radial_spectrum block:\", rs_block)\nprint(\"square block:\", squared_block)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"radial_spectrum values:\", rs_block.values)\nprint(\"square values:\", squared_block.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"radial_spectrum gradient:\", rs_block.gradient(\"positions\").values[:, 0])\nprint(\"square gradient:\", squared_block.gradient(\"positions\").values[:, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip::\n\n    We provide many functions that operate on :py:class:`TensorMap` and\n    :py:class:`TensorBlock` as part of the `metatensor-operations\n    <metatensor-operations>` module (installed by default with the main\n    ``metatensor`` package). These operations already support the different sparsity\n    levels of metatensor, and support for explicit forward gradients. In general you\n    will not have to write the type of code from this tutorial yourself, and you\n    should use the corresponding operation.\n\n    For example, ``squared`` from this tutorial can be calculated with:\n\n```python\nsquared = metatensor.multiply(radial_spectrum, radial_spectrum)\n\n# alternatively\nsquared = metatensor.pow(radial_spectrum, 2)\n```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "squared_operations = metatensor.multiply(radial_spectrum, radial_spectrum)\nprint(metatensor.equal(squared_operations, squared))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}