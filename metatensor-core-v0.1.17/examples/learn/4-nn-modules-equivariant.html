<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Custom architectures with ModuleMap" href="5-nn-using-modulemap.html" /><link rel="prev" title="Convenience nn modules" href="3-nn-modules-basic.html" />
        <link rel="prefetch" href="../../_static/images/metatensor-horizontal.png" as="image" />
        <link rel="prefetch" href="../../_static/images/metatensor-horizontal-dark.png" as="image" />

    <link rel="shortcut icon" href="../../_static/metatensor-64.png"/><!-- Generated with Sphinx 7.4.7 and Furo 2025.07.19 -->
        <title>Equivariance-preserving nn modules - Metatensor</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/metatensor.css?v=4d63172e" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Metatensor</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/images/metatensor-horizontal.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../../_static/images/metatensor-horizontal-dark.png" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../goals.html">Metatensor’s goals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../core/index.html">Core classes</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Core classes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../core/overview.html">Overview</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../core/reference/python/index.html">Python API reference</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Python API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/tensor.html">TensorMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/block.html">TensorBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/labels.html">Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/io.html">Serialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/data.html">Data arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/misc.html">Miscellaneous</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../core/reference/cxx/index.html">C++ API reference</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of C++ API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/tensor.html">TensorMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/labels.html">Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/block.html">TensorBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/data.html">Data arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/misc.html">Miscellaneous</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../core/reference/c/index.html">C API reference</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of C API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/tensor.html">TensorMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/labels.html">Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/block.html">TensorBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/data.html">Data arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/misc.html">Miscellaneous</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../core/reference/rust/index.html">Rust API reference</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../core/1-first-steps.html">First steps with metatensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/2-handling-sparsity.html">Handling sparsity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/3-managing-gradients.html">Managing gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../core/CHANGELOG.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/index.html">Operations</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Operations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/torch.html">Operations and PyTorch</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/reference/index.html">API reference</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/creation/index.html">Creation operations</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Creation operations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/empty_like.html">empty_like()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/ones_like.html">ones_like()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/zeros_like.html">zeros_like()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/random_like.html">random_like()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/block_from_array.html">block_from_array()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/linear_algebra/index.html">Linear algebra</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Linear algebra</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/linear_algebra/dot.html">dot()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/linear_algebra/lstsq.html">lstsq()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/linear_algebra/solve.html">solve()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/logic/index.html">Logic function</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Logic function</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/logic/allclose.html">allclose()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/logic/equal.html">equal()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/logic/equal-metadata.html">equal_metadata()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/logic/is-contiguous.html">is_contiguous()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/manipulation/index.html">Manipulation operations</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of Manipulation operations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/detach.html">detach()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/drop-blocks.html">drop_blocks()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/filter-blocks.html">filter_blocks()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/join.html">join()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/make-contiguous.html">make_contiguous()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/manipulate-dimension.html">manipulate dimension</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/one-hot.html">one_hot()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/remove-gradients.html">remove_gradients()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/requires-grad.html">requires_grad()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/samples-reduction.html">samples reduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/slice.html">slice()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/split.html">split()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/math/index.html">Mathematical functions</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Mathematical functions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/abs.html">abs()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/add.html">add()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/divide.html">divide()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/multiply.html">multiply()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/pow.html">pow()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/subtract.html">subtract()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/set/index.html">Set operations</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Set operations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/set/unique_metadata.html">unique_metadata()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/set/sort.html">sort()</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/reference/checks.html">Checks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/CHANGELOG.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../torch/index.html">TorchScript backend</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of TorchScript backend</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../torch/reference/index.html">API reference</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../torch/reference/tensor.html">TensorMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../torch/reference/block.html">TensorBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../torch/reference/labels.html">Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../torch/reference/serialization.html">Serialization</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../torch/reference/cxx/index.html">TorchScript C++ API reference</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of TorchScript C++ API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../torch/reference/cxx/tensor.html">TensorMap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../torch/reference/cxx/block.html">TensorBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../torch/reference/cxx/labels.html">Labels</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../torch/reference/cxx/miscellaneous.html">Miscellaneous</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../torch/CHANGELOG.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../../learn/index.html">Learning utilities</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Learning utilities</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../../learn/reference/index.html">API reference</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../learn/reference/data/index.html">Data utilites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learn/reference/nn/index.html">Neural Network building blocks</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">Tutorials</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="1-dataset-dataloader.html">Datasets and data loaders</a></li>
<li class="toctree-l3"><a class="reference internal" href="2-indexed-dataset.html">Using IndexedDataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="3-nn-modules-basic.html">Convenience <code class="docutils literal notranslate"><span class="pre">nn</span></code> modules</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Equivariance-preserving <code class="docutils literal notranslate"><span class="pre">nn</span></code> modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="5-nn-using-modulemap.html">Custom architectures with <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../learn/CHANGELOG.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../atomistic/index.html">Atomistic applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cite.html">Cite Metatensor</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../devdoc/index.html">Developer documentation</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Developer documentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../devdoc/get-started.html">Getting started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../devdoc/architecture.html">Code organization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../devdoc/versions.html">Version number management</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../../_sources/examples/learn/4-nn-modules-equivariant.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-examples-learn-4-nn-modules-equivariant-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="equivariance-preserving-nn-modules">
<span id="learn-tutorial-nn-modules-equivariant"></span><span id="sphx-glr-examples-learn-4-nn-modules-equivariant-py"></span><h1>Equivariance-preserving <code class="docutils literal notranslate"><span class="pre">nn</span></code> modules<a class="headerlink" href="#equivariance-preserving-nn-modules" title="Link to this heading">¶</a></h1>
<p>This example demonstrates the use of convenience modules in metatensor-learn to build
simple equivariance-preserving multi-layer perceptrons.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Prior to this tutorial, it is recommended to read the tutorial on <a class="reference internal" href="3-nn-modules-basic.html#learn-tutorial-nn-modules-basic"><span class="std std-ref">using
convenience modules</span></a>, as this tutorial builds on
the concepts introduced there.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">metatensor.torch</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mts</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">metatensor.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Labels</span><span class="p">,</span> <span class="n">TensorBlock</span><span class="p">,</span> <span class="n">TensorMap</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">metatensor.torch.learn.nn</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">EquivariantLinear</span><span class="p">,</span>
    <span class="n">InvariantReLU</span><span class="p">,</span>
    <span class="n">Sequential</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>Often the targets of machine learning are physical observables with certain
symmetries, such as invariance with respect to translation or equivariance with
respect to rotation (i.e., rotating the input structure means that the target
should be rotated in the same way).</p>
<p>Many successful approaches to these learning tasks use equivariance-preserving
architectures to map equivariant features onto predictions of an equivariant target.</p>
<p>In this example we will demonstrate how to build an equivariance-preserving
multi-layer perceptron (MLP) on top of some equivariant features.</p>
<p>Let’s load the spherical expansion from the <a class="reference internal" href="../core/1-first-steps.html#core-tutorial-first-steps"><span class="std std-ref">first steps tutorial</span></a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">spherical_expansion</span> <span class="o">=</span> <span class="n">mts</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;../core/spherical-expansion.mts&quot;</span><span class="p">)</span>

<span class="c1"># metatensor-learn modules currently do not support TensorMaps with gradients</span>
<span class="n">spherical_expansion</span> <span class="o">=</span> <span class="n">mts</span><span class="o">.</span><span class="n">remove_gradients</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Number of blocks in the spherical expansion:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorMap with 12 blocks
keys: o3_lambda  o3_sigma  center_type  neighbor_type
          0         1           6             6
          1         1           6             6
                           ...
          1         1           8             8
          2         1           8             8

Number of blocks in the spherical expansion: 12
</pre></div>
</div>
<p>As a reminder, these are the coefficients of the spherical-basis decompositions of a
smooth Gaussian density representation of 3D point cloud. In this case, the point
cloud is a set of decorated atomic positions.</p>
<p>The important part here is that these features are block sparse in angular momentum
channel (key dimension <code class="docutils literal notranslate"><span class="pre">&quot;o3_lambda&quot;</span></code>), with each block having a different behaviour
under rigid rotation by the SO(3) group.</p>
<p>In general, blocks that are invariant under rotation (where <code class="docutils literal notranslate"><span class="pre">o3_lambda</span> <span class="pre">==</span> <span class="pre">0</span></code>) can be
transformed in arbitrary (i.e. nonlinear) ways in the mapping from features to target,
while covariant blocks (where <code class="docutils literal notranslate"><span class="pre">o3_lambda</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>) must be transformed in a way that
preserves the equivariance of the features. The simplest way to do this is to use only
linear transformations for the latter.</p>
</section>
<section id="define-equivariant-target-data">
<h2>Define equivariant target data<a class="headerlink" href="#define-equivariant-target-data" title="Link to this heading">¶</a></h2>
<p>Let’s build some dummy target data: we will predict a global (i.e. per-system) rank-2
symmetric tensor, which decomposes into <code class="docutils literal notranslate"><span class="pre">o3_lambda</span> <span class="pre">=</span> <span class="pre">[0,</span> <span class="pre">2]</span></code> angular momenta
channels when expressed in the spherical basis. An example of such a target in
atomistic machine learning is the electronic polarizability of a molecule.</p>
<p>Our target will be block sparse with <code class="docutils literal notranslate"><span class="pre">&quot;o3_lambda&quot;</span></code> key dimensions equal to [0, 2],
and as this is a real- (not pseudo-) tensor, the inversion sigma (<code class="docutils literal notranslate"><span class="pre">&quot;o3_sigma&quot;</span></code>) will
be +1.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">target_tensormap</span> <span class="o">=</span> <span class="n">TensorMap</span><span class="p">(</span>
    <span class="n">keys</span><span class="o">=</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;o3_lambda&quot;</span><span class="p">,</span> <span class="s2">&quot;o3_sigma&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])),</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">[</span>
        <span class="n">TensorBlock</span><span class="p">(</span>
            <span class="n">values</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
            <span class="c1"># only one system</span>
            <span class="n">samples</span><span class="o">=</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;system&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])),</span>
            <span class="c1"># o3_mu = [0]</span>
            <span class="n">components</span><span class="o">=</span><span class="p">[</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;o3_mu&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">]]))],</span>
            <span class="c1"># only one &#39;property&#39; (the L=0 part of the polarizability)</span>
            <span class="n">properties</span><span class="o">=</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;_&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])),</span>
        <span class="p">),</span>
        <span class="n">TensorBlock</span><span class="p">(</span>
            <span class="n">values</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span>
            <span class="c1"># only one system</span>
            <span class="n">samples</span><span class="o">=</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;system&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])),</span>
            <span class="c1"># o3_mu = [-2, -1, 0, +1, +2]</span>
            <span class="n">components</span><span class="o">=</span><span class="p">[</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;o3_mu&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">]]))],</span>
            <span class="c1"># only one &#39;property&#39; (the L=2 part of the polarizability)</span>
            <span class="n">properties</span><span class="o">=</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;_&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">]])),</span>
        <span class="p">),</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target_tensormap</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorMap with 2 blocks
keys: o3_lambda  o3_sigma
          0         1
          2         1 TensorBlock
    samples (1): [&#39;system&#39;]
    components (1): [&#39;o3_mu&#39;]
    properties (1): [&#39;_&#39;]
    gradients: None
</pre></div>
</div>
<p>Filter the feature blocks to only keep the blocks with symmetries that match the
target: as our target only contains <code class="docutils literal notranslate"><span class="pre">o3_lambda</span> <span class="pre">=</span> <span class="pre">[0,</span> <span class="pre">2]</span></code> channels, we only need
these!</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">spherical_expansion</span> <span class="o">=</span> <span class="n">mts</span><span class="o">.</span><span class="n">filter_blocks</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="o">.</span><span class="n">keys</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Number of blocks in the filtered spherical expansion:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorMap with 8 blocks
keys: o3_lambda  o3_sigma  center_type  neighbor_type
          0         1           6             6
          2         1           6             6
                           ...
          0         1           8             8
          2         1           8             8

Number of blocks in the filtered spherical expansion: 8
</pre></div>
</div>
</section>
<section id="using-equivariant-convenience-layers">
<h2>Using equivariant convenience layers<a class="headerlink" href="#using-equivariant-convenience-layers" title="Link to this heading">¶</a></h2>
<p>Now we can build our neural network. Our architecture will consist of separate “block
models”, i.e. transformations with separate learnable weights for each block in the
spherical expansion. This is in contrast to the previous tutorial <a class="reference internal" href="3-nn-modules-basic.html#learn-tutorial-nn-modules-basic"><span class="std std-ref">nn modules
basic</span></a>, where we only had a single block in our
features and targets.</p>
<p>Furthermore, as the features are a per-atom quantity, we will use sparse tensor
operations to sum over the contributions of all atoms in the system to get a per-sytem
prediction. For this we will use <code class="docutils literal notranslate"><span class="pre">metatensor-operations</span></code>.</p>
<p>Starting simple, let’s define the neural network as just a simple linear layer. As
stated before, only linear transformations must be applied to covariant blocks, in
this case those with <code class="docutils literal notranslate"><span class="pre">o3_lambda</span> <span class="pre">=</span> <span class="pre">2</span></code>, while nonlinear transformations can be applied
to invariant blocks where <code class="docutils literal notranslate"><span class="pre">o3_lambda</span> <span class="pre">=</span> <span class="pre">0</span></code>. We will use the
<code class="xref py py-class docutils literal notranslate"><span class="pre">EquivariantLinear</span></code> module for this.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">in_keys</span> <span class="o">=</span> <span class="n">spherical_expansion</span><span class="o">.</span><span class="n">keys</span>
<span class="n">equi_linear</span> <span class="o">=</span> <span class="n">EquivariantLinear</span><span class="p">(</span>
    <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
    <span class="n">in_features</span><span class="o">=</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">],</span>
    <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># for all blocks</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">equi_linear</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Labels(
    o3_lambda  o3_sigma  center_type  neighbor_type
        0         1           6             6
        2         1           6             6
                         ...
        0         1           8             8
        2         1           8             8
)
EquivariantLinear(
  (module_map): ModuleMap(
    (0): Linear(in_features=5, out_features=1, bias=True)
    (1): Linear(in_features=5, out_features=1, bias=False)
    (2): Linear(in_features=5, out_features=1, bias=True)
    (3): Linear(in_features=5, out_features=1, bias=False)
    (4): Linear(in_features=5, out_features=1, bias=True)
    (5): Linear(in_features=5, out_features=1, bias=False)
    (6): Linear(in_features=5, out_features=1, bias=True)
    (7): Linear(in_features=5, out_features=1, bias=False)
  )
)
</pre></div>
</div>
<p>We can see by printing the architecture of the <code class="docutils literal notranslate"><span class="pre">EquivariantLinear</span></code> module,
that there are 8 ‘Linear’ layers, one for each block. In order to preserve
equivariance, bias is always turned off for all covariant blocks. For
invariant blocks, bias can be switched on or off by passing the boolean
parameter <code class="docutils literal notranslate"><span class="pre">bias</span></code> when initializing <code class="docutils literal notranslate"><span class="pre">EquivariantLinear</span></code> objects.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s see what happens when we pass features through the network.</span>
<span class="n">per_atom_predictions</span> <span class="o">=</span> <span class="n">equi_linear</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">per_atom_predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">per_atom_predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorMap with 8 blocks
keys: o3_lambda  o3_sigma  center_type  neighbor_type
          0         1           6             6
          2         1           6             6
                           ...
          0         1           8             8
          2         1           8             8
TensorBlock
    samples (1): [&#39;system&#39;, &#39;atom&#39;]
    components (1): [&#39;o3_mu&#39;]
    properties (1): [&#39;_&#39;]
    gradients: None
</pre></div>
</div>
<p>The outputs of the <code class="docutils literal notranslate"><span class="pre">EquivariantLinear</span></code> module are still per-atom and block sparse in
both “center_type” and “neighbor_type”. To get per-system predictions, we can
“densify” the predictions in these key dimensions by moving them to samples,
then taking the sum over all sample dimensions except “system”.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">per_atom_predictions</span> <span class="o">=</span> <span class="n">per_atom_predictions</span><span class="o">.</span><span class="n">keys_to_samples</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;center_type&quot;</span><span class="p">,</span> <span class="s2">&quot;neighbor_type&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">per_system_predictions</span> <span class="o">=</span> <span class="n">mts</span><span class="o">.</span><span class="n">sum_over_samples</span><span class="p">(</span>
    <span class="n">per_atom_predictions</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;atom&quot;</span><span class="p">,</span> <span class="s2">&quot;center_type&quot;</span><span class="p">,</span> <span class="s2">&quot;neighbor_type&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="k">assert</span> <span class="n">mts</span><span class="o">.</span><span class="n">equal_metadata</span><span class="p">(</span><span class="n">per_system_predictions</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">per_system_predictions</span><span class="p">,</span> <span class="n">per_system_predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TensorMap with 2 blocks
keys: o3_lambda  o3_sigma
          0         1
          2         1 TensorBlock
    samples (1): [&#39;system&#39;]
    components (1): [&#39;o3_mu&#39;]
    properties (1): [&#39;_&#39;]
    gradients: None
</pre></div>
</div>
<p>The overall ‘model’ that maps features to targets contains both the application of a
neural network and some extra transformations, we can wrap it all in a single torch
module.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">EquivariantMLP</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A simple equivariant MLP that maps per-atom features to per-structure targets.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mlp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">mlp</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">TensorMap</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorMap</span><span class="p">:</span>
        <span class="c1"># apply the multi-layer perceptron to the features</span>
        <span class="n">per_atom_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># densify the predictions in the &quot;center_type&quot; and &quot;neighbor_type&quot; key</span>
        <span class="c1"># dimensions</span>
        <span class="n">per_atom_predictions</span> <span class="o">=</span> <span class="n">per_atom_predictions</span><span class="o">.</span><span class="n">keys_to_samples</span><span class="p">(</span>
            <span class="p">[</span><span class="s2">&quot;center_type&quot;</span><span class="p">,</span> <span class="s2">&quot;neighbor_type&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># sum over all sample dimensions except &quot;system&quot;</span>
        <span class="n">per_system_predictions</span> <span class="o">=</span> <span class="n">mts</span><span class="o">.</span><span class="n">sum_over_samples</span><span class="p">(</span>
            <span class="n">per_atom_predictions</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;atom&quot;</span><span class="p">,</span> <span class="s2">&quot;center_type&quot;</span><span class="p">,</span> <span class="s2">&quot;neighbor_type&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">per_system_predictions</span>
</pre></div>
</div>
<p>Now we will construct the loss function and run the training loop as we did in the
previous tutorial, <a class="reference internal" href="3-nn-modules-basic.html#learn-tutorial-nn-modules-basic"><span class="std std-ref">nn modules basic</span></a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define a custom loss function for TensorMaps that computes the squared error and</span>
<span class="c1"># reduces by a summation operation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TensorMapLoss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A custom loss function for TensorMaps that computes the squared error and reduces by</span>
<span class="sd">    sum.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_input</span><span class="p">:</span> <span class="n">TensorMap</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">TensorMap</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the total squared error between the ``_input`` and ``target``</span>
<span class="sd">        TensorMaps.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># inputs and targets should have the same metadata over all axes</span>
        <span class="k">assert</span> <span class="n">mts</span><span class="o">.</span><span class="n">equal_metadata</span><span class="p">(</span><span class="n">_input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="n">squared_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">_input</span><span class="o">.</span><span class="n">keys</span><span class="p">:</span>
            <span class="n">squared_loss</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">_input</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">target</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">squared_loss</span>


<span class="c1"># construct a basic training loop. For brevity we will not use datasets or dataloaders.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">training_loop</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">features</span><span class="p">:</span> <span class="n">TensorMap</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">TensorMap</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A basic training loop for a model and loss function.&quot;&quot;&quot;</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">301</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">mts</span><span class="o">.</span><span class="n">equal_metadata</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="n">loss_fn_mts</span> <span class="o">=</span> <span class="n">TensorMapLoss</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">EquivariantMLP</span><span class="p">(</span><span class="n">equi_linear</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;with NN = [EquivariantLinear]&quot;</span><span class="p">)</span>
<span class="n">training_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn_mts</span><span class="p">,</span> <span class="n">spherical_expansion</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>with NN = [EquivariantLinear]
epoch: 0, loss: 1.809741514725238
epoch: 100, loss: 1.4297721240098198
epoch: 200, loss: 1.369045943496478
epoch: 300, loss: 1.3525927125547264
</pre></div>
</div>
<p>Let’s inspect the per-block losses using predictions from the trained model. Note that
the model is able to perfectly fit the invariant target blocks, but not the covariant
blocks. This is to be expected, as the target data was generated with random numbers
and is not itself equivariant, making the learning task impossible.</p>
<p>See also the atomistic cookbook example on rotational equivariance for a more detailed
discussion of this topic:
<a class="reference external" href="https://atomistic-cookbook.org/examples/rotate-equivariants/rotate-equivariants.html">https://atomistic-cookbook.org/examples/rotate-equivariants/rotate-equivariants.html</a></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;per-block loss:&quot;</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">prediction</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">block</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">target_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>per-block loss:
LabelsEntry(o3_lambda=0, o3_sigma=1) 9.874580335918655e-15
LabelsEntry(o3_lambda=2, o3_sigma=1) 1.3525269172807264
</pre></div>
</div>
<p>Now let’s consider a more complex nonlinear architecture. In the simplest case we are
restricted to linear layers for covariant blocks, but we can use nonlinear layers for
invariant blocks.</p>
<p>We will use the <code class="xref py py-class docutils literal notranslate"><span class="pre">InvariantReLU</span></code> activation
function. It has the prefix “Invariant” as it only applies the activation function to
invariant blocks where <code class="docutils literal notranslate"><span class="pre">o3_lambda</span> <span class="pre">=</span> <span class="pre">0</span></code>, and leaves the covariant blocks unchanged.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s build a new MLP with two linear layers and one activation function.</span>
<span class="n">hidden_layer_width</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">equi_mlp</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span>
    <span class="n">in_keys</span><span class="p">,</span>
    <span class="n">EquivariantLinear</span><span class="p">(</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
        <span class="n">in_features</span><span class="o">=</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">],</span>
        <span class="n">out_features</span><span class="o">=</span><span class="n">hidden_layer_width</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">InvariantReLU</span><span class="p">(</span><span class="n">in_keys</span><span class="p">),</span>  <span class="c1"># could also use InvariantTanh, InvariantSiLU</span>
    <span class="n">EquivariantLinear</span><span class="p">(</span>
        <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
        <span class="n">in_features</span><span class="o">=</span><span class="p">[</span><span class="n">hidden_layer_width</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">],</span>
        <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># for all blocks</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">in_keys</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">equi_mlp</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Labels(
    o3_lambda  o3_sigma  center_type  neighbor_type
        0         1           6             6
        2         1           6             6
                         ...
        0         1           8             8
        2         1           8             8
)
Sequential(
  (module_map): ModuleMap(
    (0): Sequential(
      (0): Linear(in_features=5, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
    (1): Sequential(
      (0): Linear(in_features=5, out_features=64, bias=False)
      (1): Identity()
      (2): Linear(in_features=64, out_features=1, bias=False)
    )
    (2): Sequential(
      (0): Linear(in_features=5, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
    (3): Sequential(
      (0): Linear(in_features=5, out_features=64, bias=False)
      (1): Identity()
      (2): Linear(in_features=64, out_features=1, bias=False)
    )
    (4): Sequential(
      (0): Linear(in_features=5, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
    (5): Sequential(
      (0): Linear(in_features=5, out_features=64, bias=False)
      (1): Identity()
      (2): Linear(in_features=64, out_features=1, bias=False)
    )
    (6): Sequential(
      (0): Linear(in_features=5, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=1, bias=True)
    )
    (7): Sequential(
      (0): Linear(in_features=5, out_features=64, bias=False)
      (1): Identity()
      (2): Linear(in_features=64, out_features=1, bias=False)
    )
  )
)
</pre></div>
</div>
<p>Notice that for invariant blocks, the ‘block model’ is a nonlinear MLP whereas for
invariant blocks it is the sequential application of two linear layers, without bias.
Re-running the training loop with this new architecture:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">EquivariantMLP</span><span class="p">(</span><span class="n">equi_mlp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;with NN = [EquivariantLinear, InvariantSiLU, EquivariantLinear]&quot;</span><span class="p">)</span>
<span class="n">training_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn_mts</span><span class="p">,</span> <span class="n">spherical_expansion</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>with NN = [EquivariantLinear, InvariantSiLU, EquivariantLinear]
epoch: 0, loss: 1.4347149592840838
epoch: 100, loss: 1.3492204184722987
epoch: 200, loss: 1.3492187581772856
epoch: 300, loss: 1.3492187581534367
</pre></div>
</div>
<p>With the trained model, let’s see the per-block decomposition of the loss. As before,
the model can perfectly fit the invariants, but not the covariants, as expected.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;per-block loss:&quot;</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">spherical_expansion</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">prediction</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">block</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">target_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>per-block loss:
LabelsEntry(o3_lambda=0, o3_sigma=1) 5.353718304873162e-16
LabelsEntry(o3_lambda=2, o3_sigma=1) 1.3492187581534363
</pre></div>
</div>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">¶</a></h2>
<p>This tutorial has demonstrated how to build equivariance-preserving architectures
using the metatensor-learn convenience neural network modules. These modules, such as
<code class="docutils literal notranslate"><span class="pre">EquivariantLinear</span></code> and <code class="docutils literal notranslate"><span class="pre">InvariantReLU</span></code> are modified analogs of the standard
convenience layers, such as <code class="docutils literal notranslate"><span class="pre">Linear</span></code> and <code class="docutils literal notranslate"><span class="pre">ReLU</span></code>.</p>
<p>The key difference is that the invariant or covariant nature (via the “o3_lambda” key
dimension) of the input blocks are taken into account, and used to determine the
transformations applied to each block.</p>
</section>
<section id="other-examples">
<h2>Other examples<a class="headerlink" href="#other-examples" title="Link to this heading">¶</a></h2>
<p>See the atomistic cookbook for an example on learning the polarizability using
<code class="docutils literal notranslate"><span class="pre">EquivariantLinear</span></code> applied to higher body order features:</p>
<p><a class="reference external" href="https://atomistic-cookbook.org/examples/polarizability/polarizability.html">https://atomistic-cookbook.org/examples/polarizability/polarizability.html</a></p>
<p>and those for checking the rotational equivariance of quantities in <code class="docutils literal notranslate"><span class="pre">TensorMap</span></code>
format:</p>
<p><a class="reference external" href="https://atomistic-cookbook.org/examples/rotate-equivariants/rotate-equivariants.html">https://atomistic-cookbook.org/examples/rotate-equivariants/rotate-equivariants.html</a></p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 3.610 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-learn-4-nn-modules-equivariant-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/1e8b745f34801b882562f0320a30b289/4-nn-modules-equivariant.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">4-nn-modules-equivariant.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/5d761893b88dc5362a2312d23e392d75/4-nn-modules-equivariant.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">4-nn-modules-equivariant.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/df7b9ad2a829013abd3e632044a9ba8a/4-nn-modules-equivariant.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">4-nn-modules-equivariant.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="5-nn-using-modulemap.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Custom architectures with <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code></div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="3-nn-modules-basic.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Convenience <code class="docutils literal notranslate"><span class="pre">nn</span></code> modules</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, the metatensor developers
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Equivariance-preserving <code class="docutils literal notranslate"><span class="pre">nn</span></code> modules</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#define-equivariant-target-data">Define equivariant target data</a></li>
<li><a class="reference internal" href="#using-equivariant-convenience-layers">Using equivariant convenience layers</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li><a class="reference internal" href="#other-examples">Other examples</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../../_static/toggleprompt.js?v=5801b3bb"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../_static/js/custom.js?v=4b1677b9"></script>
    <script data-domain="docs.metatensor.org" defer="defer" src="https://plausible.io/js/script.js"></script>
    </body>
</html>