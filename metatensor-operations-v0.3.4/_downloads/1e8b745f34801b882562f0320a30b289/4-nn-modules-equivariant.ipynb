{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Equivariance-preserving ``nn`` modules\n\n.. py:currentmodule:: metatensor.torch.learn.nn\n\nThis example demonstrates the use of convenience modules in metatensor-learn to build\nsimple equivariance-preserving multi-layer perceptrons.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Prior to this tutorial, it is recommended to read the tutorial on `using\n    convenience modules <learn-tutorial-nn-modules-basic>`, as this tutorial builds on\n    the concepts introduced there.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nimport metatensor.torch as mts\nfrom metatensor.torch import Labels, TensorBlock, TensorMap\nfrom metatensor.torch.learn.nn import (\n    EquivariantLinear,\n    InvariantReLU,\n    Sequential,\n)\n\n\ntorch.manual_seed(42)\ntorch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n\nOften the targets of machine learning are physical observables with certain\nsymmetries, such as invariance with respect to translation or equivariance with\nrespect to rotation (i.e., rotating the input structure means that the target\nshould be rotated in the same way).\n\nMany successful approaches to these learning tasks use equivariance-preserving\narchitectures to map equivariant features onto predictions of an equivariant target.\n\nIn this example we will demonstrate how to build an equivariance-preserving\nmulti-layer perceptron (MLP) on top of some equivariant features.\n\nLet's load the spherical expansion from the `first steps tutorial\n<core-tutorial-first-steps>`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spherical_expansion = mts.load(\"../core/spherical-expansion.mts\")\n\n# metatensor-learn modules currently do not support TensorMaps with gradients\nspherical_expansion = mts.remove_gradients(spherical_expansion)\nprint(spherical_expansion)\nprint(\"\\nNumber of blocks in the spherical expansion:\", len(spherical_expansion))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a reminder, these are the coefficients of the spherical-basis decompositions of a\nsmooth Gaussian density representation of 3D point cloud. In this case, the point\ncloud is a set of decorated atomic positions.\n\nThe important part here is that these features are block sparse in angular momentum\nchannel (key dimension ``\"o3_lambda\"``), with each block having a different behaviour\nunder rigid rotation by the SO(3) group.\n\nIn general, blocks that are invariant under rotation (where ``o3_lambda == 0``) can be\ntransformed in arbitrary (i.e. nonlinear) ways in the mapping from features to target,\nwhile covariant blocks (where ``o3_lambda > 0``) must be transformed in a way that\npreserves the equivariance of the features. The simplest way to do this is to use only\nlinear transformations for the latter.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define equivariant target data\n\nLet's build some dummy target data: we will predict a global (i.e. per-system) rank-2\nsymmetric tensor, which decomposes into ``o3_lambda = [0, 2]`` angular momenta\nchannels when expressed in the spherical basis. An example of such a target in\natomistic machine learning is the electronic polarizability of a molecule.\n\nOur target will be block sparse with ``\"o3_lambda\"`` key dimensions equal to [0, 2],\nand as this is a real- (not pseudo-) tensor, the inversion sigma (``\"o3_sigma\"``) will\nbe +1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_tensormap = TensorMap(\n    keys=Labels([\"o3_lambda\", \"o3_sigma\"], torch.tensor([[0, 1], [2, 1]])),\n    blocks=[\n        TensorBlock(\n            values=torch.randn((1, 1, 1), dtype=torch.float64),\n            # only one system\n            samples=Labels([\"system\"], torch.tensor([[0]])),\n            # o3_mu = [0]\n            components=[Labels([\"o3_mu\"], torch.tensor([[0]]))],\n            # only one 'property' (the L=0 part of the polarizability)\n            properties=Labels([\"_\"], torch.tensor([[0]])),\n        ),\n        TensorBlock(\n            values=torch.randn((1, 5, 1), dtype=torch.float64),\n            # only one system\n            samples=Labels([\"system\"], torch.tensor([[0]])),\n            # o3_mu = [-2, -1, 0, +1, +2]\n            components=[Labels([\"o3_mu\"], torch.tensor([[-2], [-1], [0], [1], [2]]))],\n            # only one 'property' (the L=2 part of the polarizability)\n            properties=Labels([\"_\"], torch.tensor([[0]])),\n        ),\n    ],\n)\nprint(target_tensormap, target_tensormap[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter the feature blocks to only keep the blocks with symmetries that match the\ntarget: as our target only contains ``o3_lambda = [0, 2]`` channels, we only need\nthese!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spherical_expansion = mts.filter_blocks(spherical_expansion, target_tensormap.keys)\nprint(spherical_expansion)\nprint(\n    \"\\nNumber of blocks in the filtered spherical expansion:\", len(spherical_expansion)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using equivariant convenience layers\n\nNow we can build our neural network. Our architecture will consist of separate \"block\nmodels\", i.e. transformations with separate learnable weights for each block in the\nspherical expansion. This is in contrast to the previous tutorial `nn modules\nbasic <learn-tutorial-nn-modules-basic>`, where we only had a single block in our\nfeatures and targets.\n\nFurthermore, as the features are a per-atom quantity, we will use sparse tensor\noperations to sum over the contributions of all atoms in the system to get a per-sytem\nprediction. For this we will use ``metatensor-operations``.\n\nStarting simple, let's define the neural network as just a simple linear layer. As\nstated before, only linear transformations must be applied to covariant blocks, in\nthis case those with ``o3_lambda = 2``, while nonlinear transformations can be applied\nto invariant blocks where ``o3_lambda = 0``. We will use the\n:py:class:`~metatensor.torch.learn.nn.EquivariantLinear` module for this.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "in_keys = spherical_expansion.keys\nequi_linear = EquivariantLinear(\n    in_keys=in_keys,\n    in_features=[len(spherical_expansion[key].properties) for key in in_keys],\n    out_features=1,  # for all blocks\n)\nprint(in_keys)\nprint(equi_linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see by printing the architecture of the ``EquivariantLinear`` module,\nthat there are 8 'Linear' layers, one for each block. In order to preserve\nequivariance, bias is always turned off for all covariant blocks. For\ninvariant blocks, bias can be switched on or off by passing the boolean\nparameter ``bias`` when initializing ``EquivariantLinear`` objects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's see what happens when we pass features through the network.\nper_atom_predictions = equi_linear(spherical_expansion)\nprint(per_atom_predictions)\nprint(per_atom_predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The outputs of the ``EquivariantLinear`` module are still per-atom and block sparse in\nboth \"center_type\" and \"neighbor_type\". To get per-system predictions, we can\n\"densify\" the predictions in these key dimensions by moving them to samples,\nthen taking the sum over all sample dimensions except \"system\".\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "per_atom_predictions = per_atom_predictions.keys_to_samples(\n    [\"center_type\", \"neighbor_type\"]\n)\nper_system_predictions = mts.sum_over_samples(\n    per_atom_predictions, [\"atom\", \"center_type\", \"neighbor_type\"]\n)\nassert mts.equal_metadata(per_system_predictions, target_tensormap)\nprint(per_system_predictions, per_system_predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overall 'model' that maps features to targets contains both the application of a\nneural network and some extra transformations, we can wrap it all in a single torch\nmodule.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class EquivariantMLP(torch.nn.Module):\n    \"\"\"\n    A simple equivariant MLP that maps per-atom features to per-structure targets.\n    \"\"\"\n\n    def __init__(self, mlp: torch.nn.Module):\n        super().__init__()\n        self.mlp = mlp\n\n    def forward(self, features: TensorMap) -> TensorMap:\n        # apply the multi-layer perceptron to the features\n        per_atom_predictions = self.mlp(features)\n\n        # densify the predictions in the \"center_type\" and \"neighbor_type\" key\n        # dimensions\n        per_atom_predictions = per_atom_predictions.keys_to_samples(\n            [\"center_type\", \"neighbor_type\"]\n        )\n\n        # sum over all sample dimensions except \"system\"\n        per_system_predictions = mts.sum_over_samples(\n            per_atom_predictions, [\"atom\", \"center_type\", \"neighbor_type\"]\n        )\n\n        return per_system_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will construct the loss function and run the training loop as we did in the\nprevious tutorial, `nn modules basic <learn-tutorial-nn-modules-basic>`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# define a custom loss function for TensorMaps that computes the squared error and\n# reduces by a summation operation\nclass TensorMapLoss(torch.nn.Module):\n    \"\"\"\n    A custom loss function for TensorMaps that computes the squared error and reduces by\n    sum.\n    \"\"\"\n\n    def __init__(self) -> None:\n        super().__init__()\n\n    def forward(self, _input: TensorMap, target: TensorMap) -> torch.Tensor:\n        \"\"\"\n        Computes the total squared error between the ``_input`` and ``target``\n        TensorMaps.\n        \"\"\"\n        # inputs and targets should have the same metadata over all axes\n        assert mts.equal_metadata(_input, target)\n\n        squared_loss = 0\n        for key in _input.keys:\n            squared_loss += torch.sum((_input[key].values - target[key].values) ** 2)\n\n        return squared_loss\n\n\n# construct a basic training loop. For brevity we will not use datasets or dataloaders.\ndef training_loop(\n    model: torch.nn.Module,\n    loss_fn: torch.nn.Module,\n    features: TensorMap,\n    targets: TensorMap,\n) -> None:\n    \"\"\"A basic training loop for a model and loss function.\"\"\"\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    for epoch in range(301):\n        optimizer.zero_grad()\n\n        predictions = model(features)\n\n        assert mts.equal_metadata(predictions, targets)\n\n        loss = loss_fn(predictions, targets)\n        loss.backward()\n        optimizer.step()\n\n        if epoch % 100 == 0:\n            print(f\"epoch: {epoch}, loss: {loss}\")\n\n\nloss_fn_mts = TensorMapLoss()\nmodel = EquivariantMLP(equi_linear)\nprint(\"with NN = [EquivariantLinear]\")\ntraining_loop(model, loss_fn_mts, spherical_expansion, target_tensormap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect the per-block losses using predictions from the trained model. Note that\nthe model is able to perfectly fit the invariant target blocks, but not the covariant\nblocks. This is to be expected, as the target data was generated with random numbers\nand is not itself equivariant, making the learning task impossible.\n\nSee also the atomistic cookbook example on rotational equivariance for a more detailed\ndiscussion of this topic:\nhttps://atomistic-cookbook.org/examples/rotate-equivariants/rotate-equivariants.html\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"per-block loss:\")\nprediction = model(spherical_expansion)\nfor key, block in prediction.items():\n    print(key, torch.sum((block.values - target_tensormap[key].values) ** 2).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's consider a more complex nonlinear architecture. In the simplest case we are\nrestricted to linear layers for covariant blocks, but we can use nonlinear layers for\ninvariant blocks.\n\nWe will use the :py:class:`~metatensor.torch.learn.nn.InvariantReLU` activation\nfunction. It has the prefix \"Invariant\" as it only applies the activation function to\ninvariant blocks where ``o3_lambda = 0``, and leaves the covariant blocks unchanged.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's build a new MLP with two linear layers and one activation function.\nhidden_layer_width = 64\nequi_mlp = Sequential(\n    in_keys,\n    EquivariantLinear(\n        in_keys=in_keys,\n        in_features=[len(spherical_expansion[key].properties) for key in in_keys],\n        out_features=hidden_layer_width,\n    ),\n    InvariantReLU(in_keys),  # could also use InvariantTanh, InvariantSiLU\n    EquivariantLinear(\n        in_keys=in_keys,\n        in_features=[hidden_layer_width for _ in in_keys],\n        out_features=1,  # for all blocks\n    ),\n)\nprint(in_keys)\nprint(equi_mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that for invariant blocks, the 'block model' is a nonlinear MLP whereas for\ninvariant blocks it is the sequential application of two linear layers, without bias.\nRe-running the training loop with this new architecture:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = EquivariantMLP(equi_mlp)\nprint(\"with NN = [EquivariantLinear, InvariantSiLU, EquivariantLinear]\")\ntraining_loop(model, loss_fn_mts, spherical_expansion, target_tensormap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the trained model, let's see the per-block decomposition of the loss. As before,\nthe model can perfectly fit the invariants, but not the covariants, as expected.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"per-block loss:\")\nprediction = model(spherical_expansion)\nfor key, block in prediction.items():\n    print(key, torch.sum((block.values - target_tensormap[key].values) ** 2).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nThis tutorial has demonstrated how to build equivariance-preserving architectures\nusing the metatensor-learn convenience neural network modules. These modules, such as\n``EquivariantLinear`` and ``InvariantReLU`` are modified analogs of the standard\nconvenience layers, such as ``Linear`` and ``ReLU``.\n\nThe key difference is that the invariant or covariant nature (via the \"o3_lambda\" key\ndimension) of the input blocks are taken into account, and used to determine the\ntransformations applied to each block.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other examples\n\nSee the atomistic cookbook for an example on learning the polarizability using\n``EquivariantLinear`` applied to higher body order features:\n\nhttps://atomistic-cookbook.org/examples/polarizability/polarizability.html\n\nand those for checking the rotational equivariance of quantities in ``TensorMap``\nformat:\n\nhttps://atomistic-cookbook.org/examples/rotate-equivariants/rotate-equivariants.html\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}