<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Changelog" href="../../learn/CHANGELOG.html" /><link rel="prev" title="Equivariance-preserving nn modules" href="4-nn-modules-equivariant.html" />
        <link rel="prefetch" href="../../_static/images/metatensor-horizontal.png" as="image" />
        <link rel="prefetch" href="../../_static/images/metatensor-horizontal-dark.png" as="image" />

    <link rel="shortcut icon" href="../../_static/metatensor-64.png"/><!-- Generated with Sphinx 7.4.7 and Furo 2025.07.19 -->
        <title>Custom architectures with ModuleMap - Metatensor</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=25af2a20" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/metatensor.css?v=4d63172e" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=8dab3a3b" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #2b2b2b;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Metatensor</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../../_static/images/metatensor-horizontal.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../../_static/images/metatensor-horizontal-dark.png" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../goals.html">Metatensor’s goals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../core/index.html">Core classes</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Core classes</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../core/overview.html">Overview</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../core/reference/python/index.html">Python API reference</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Python API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/tensor.html">TensorMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/block.html">TensorBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/labels.html">Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/io.html">Serialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/data.html">Data arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/python/misc.html">Miscellaneous</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../core/reference/cxx/index.html">C++ API reference</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of C++ API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/tensor.html">TensorMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/labels.html">Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/block.html">TensorBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/data.html">Data arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/cxx/misc.html">Miscellaneous</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../core/reference/c/index.html">C API reference</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of C API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/tensor.html">TensorMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/labels.html">Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/block.html">TensorBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/data.html">Data arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../core/reference/c/misc.html">Miscellaneous</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../core/reference/rust/index.html">Rust API reference</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../core/1-first-steps.html">First steps with metatensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/2-handling-sparsity.html">Handling sparsity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core/3-managing-gradients.html">Managing gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../core/CHANGELOG.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../operations/index.html">Operations</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Operations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../operations/torch.html">Operations and PyTorch</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../operations/reference/index.html">API reference</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/creation/index.html">Creation operations</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Creation operations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/empty_like.html">empty_like()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/ones_like.html">ones_like()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/zeros_like.html">zeros_like()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/random_like.html">random_like()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/creation/block_from_array.html">block_from_array()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/linear_algebra/index.html">Linear algebra</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Linear algebra</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/linear_algebra/dot.html">dot()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/linear_algebra/lstsq.html">lstsq()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/linear_algebra/solve.html">solve()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/logic/index.html">Logic function</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Logic function</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/logic/allclose.html">allclose()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/logic/equal.html">equal()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/logic/equal-metadata.html">equal_metadata()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/logic/is-contiguous.html">is_contiguous()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/manipulation/index.html">Manipulation operations</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of Manipulation operations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/detach.html">detach()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/drop-blocks.html">drop_blocks()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/filter-blocks.html">filter_blocks()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/join.html">join()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/make-contiguous.html">make_contiguous()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/manipulate-dimension.html">manipulate dimension</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/one-hot.html">one_hot()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/remove-gradients.html">remove_gradients()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/requires-grad.html">requires_grad()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/samples-reduction.html">samples reduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/slice.html">slice()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/manipulation/split.html">split()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/math/index.html">Mathematical functions</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Mathematical functions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/abs.html">abs()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/add.html">add()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/divide.html">divide()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/multiply.html">multiply()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/pow.html">pow()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/math/subtract.html">subtract()</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../operations/reference/set/index.html">Set operations</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of Set operations</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/set/unique_metadata.html">unique_metadata()</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../operations/reference/set/sort.html">sort()</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../operations/reference/checks.html">Checks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../operations/CHANGELOG.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../torch/index.html">TorchScript backend</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of TorchScript backend</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../torch/reference/index.html">API reference</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../torch/reference/tensor.html">TensorMap</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../torch/reference/block.html">TensorBlock</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../torch/reference/labels.html">Labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../torch/reference/serialization.html">Serialization</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../torch/reference/cxx/index.html">TorchScript C++ API reference</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of TorchScript C++ API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../torch/reference/cxx/tensor.html">TensorMap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../torch/reference/cxx/block.html">TensorBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../torch/reference/cxx/labels.html">Labels</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../torch/reference/cxx/miscellaneous.html">Miscellaneous</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../torch/CHANGELOG.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../../learn/index.html">Learning utilities</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of Learning utilities</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../../learn/reference/index.html">API reference</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../learn/reference/data/index.html">Data utilites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../learn/reference/nn/index.html">Neural Network building blocks</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">Tutorials</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="1-dataset-dataloader.html">Datasets and data loaders</a></li>
<li class="toctree-l3"><a class="reference internal" href="2-indexed-dataset.html">Using IndexedDataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="3-nn-modules-basic.html">Convenience <code class="docutils literal notranslate"><span class="pre">nn</span></code> modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="4-nn-modules-equivariant.html">Equivariance-preserving <code class="docutils literal notranslate"><span class="pre">nn</span></code> modules</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">Custom architectures with <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../learn/CHANGELOG.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../atomistic/index.html">Atomistic applications</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../devdoc/index.html">Developer documentation</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of Developer documentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../devdoc/get-started.html">Getting started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../devdoc/architecture.html">Code organization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../devdoc/versions.html">Version number management</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../../_sources/examples/learn/5-nn-using-modulemap.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-examples-learn-5-nn-using-modulemap-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="custom-architectures-with-modulemap">
<span id="learn-tutorial-nn-using-modulemap"></span><span id="sphx-glr-examples-learn-5-nn-using-modulemap-py"></span><h1>Custom architectures with <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code><a class="headerlink" href="#custom-architectures-with-modulemap" title="Link to this heading">¶</a></h1>
<p>This tutorial demonstrates how to build custom architectures compatible with
<code class="docutils literal notranslate"><span class="pre">TensorMap</span></code> objects by combining native <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> modules with metatensor-learn’s
<code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Prior to this tutorial, it is recommended to read the tutorial on <a class="reference internal" href="3-nn-modules-basic.html#learn-tutorial-nn-modules-basic"><span class="std std-ref">using
convenience modules</span></a>, as this tutorial builds on
the concepts introduced there.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">metatensor.torch</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mts</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">metatensor.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">Labels</span><span class="p">,</span> <span class="n">TensorMap</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">metatensor.torch.learn.nn</span><span class="w"> </span><span class="kn">import</span> <span class="n">Linear</span><span class="p">,</span> <span class="n">ModuleMap</span>


<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_default_dtype</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>The previous tutorials cover how to use metatensor learn’s <code class="docutils literal notranslate"><span class="pre">nn</span></code> convenience modules
to build simple multi-layer perceptrons and their equivariance-preserving analogs. Now
we will explore the use of a special module called <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code> that allows users to
wrap any native torch module in a <code class="docutils literal notranslate"><span class="pre">TensorMap</span></code> compatible manner.</p>
<p>This is useful for building arbitrary architectures containing layers more
complex than those found in the standard available layers: namely <code class="docutils literal notranslate"><span class="pre">Linear</span></code>,
<code class="docutils literal notranslate"><span class="pre">Tanh</span></code>, <code class="docutils literal notranslate"><span class="pre">ReLU</span></code>, <code class="docutils literal notranslate"><span class="pre">SiLU</span></code> and <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> and their equivariant
counterparts.</p>
<p>First we need to create some dummy data in the <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorMap</span></code> format,
with multiple <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorBlock</span></code> objects. Here we will focus on
unconstrained architectures, as opposed to equivariance preserving ones. The
principles in the latter case will be similar, as long as care is taken to
build architectures with equivarince-preserving transformations.</p>
<p>Let’s start by defining a random tensor that we will treat as some
intermediate representation. We will build a multi-layer perceptron to
transform this tensor into a prediction. Here we will define a 3-block tensor
map, with variables with the in and out dimensions for each block.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">in_features</span> <span class="o">=</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span>
<span class="n">out_features</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="n">feature_tensormap</span> <span class="o">=</span> <span class="n">TensorMap</span><span class="p">(</span>
    <span class="n">keys</span><span class="o">=</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;key&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">out_features</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">[</span>
        <span class="n">mts</span><span class="o">.</span><span class="n">block_from_array</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">in_feats</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">in_feats</span> <span class="ow">in</span> <span class="n">in_features</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="n">target_tensormap</span> <span class="o">=</span> <span class="n">TensorMap</span><span class="p">(</span>
    <span class="n">keys</span><span class="o">=</span><span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;key&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">out_features</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">blocks</span><span class="o">=</span><span class="p">[</span>
        <span class="n">mts</span><span class="o">.</span><span class="n">block_from_array</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">out_feats</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">out_feats</span> <span class="ow">in</span> <span class="n">out_features</span>
    <span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;features:&quot;</span><span class="p">,</span> <span class="n">feature_tensormap</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;target:&quot;</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>features: TensorMap with 3 blocks
keys: key
       0
       1
       2
target: TensorMap with 3 blocks
keys: key
       0
       1
       2
</pre></div>
</div>
</section>
<section id="starting-simple">
<h2>Starting simple<a class="headerlink" href="#starting-simple" title="Link to this heading">¶</a></h2>
<p>Let’s start with a simple linear layer, but this time constructed manually using
<code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code>. Here we want a linear layer for each block, with the correct in and out
feature shapes. The result will be a module that is equivalent to the
<code class="docutils literal notranslate"><span class="pre">metatensor.torch.learn.nn.Linear</span></code> module.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">in_keys</span> <span class="o">=</span> <span class="n">feature_tensormap</span><span class="o">.</span><span class="n">keys</span>

<span class="n">modules</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">:</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
        <span class="n">in_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span><span class="p">),</span>
        <span class="n">out_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">target_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span><span class="p">),</span>
        <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

<span class="c1"># initialize the ModuleMap with the input keys, list of modules, and the output</span>
<span class="c1"># property labels&#39; metadata.</span>
<span class="n">linear_mmap</span> <span class="o">=</span> <span class="n">ModuleMap</span><span class="p">(</span>
    <span class="n">in_keys</span><span class="p">,</span>
    <span class="n">modules</span><span class="p">,</span>
    <span class="n">out_properties</span><span class="o">=</span><span class="p">[</span><span class="n">target_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">linear_mmap</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ModuleMap(
  (0): Linear(in_features=64, out_features=1, bias=True)
  (1): Linear(in_features=128, out_features=2, bias=True)
  (2): Linear(in_features=256, out_features=3, bias=True)
)
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code> automatically handles the forward pass for each block indexed by
the <code class="docutils literal notranslate"><span class="pre">in_keys</span></code> used to initialize it. In cases where the input contains more
keys/blocks than what is present in the <code class="docutils literal notranslate"><span class="pre">in_keys`</span> <span class="pre">field,</span> <span class="pre">the</span> <span class="pre">forward</span> <span class="pre">pass</span>
<span class="pre">will</span> <span class="pre">only</span> <span class="pre">be</span> <span class="pre">applied</span> <span class="pre">to</span> <span class="pre">the</span> <span class="pre">blocks</span> <span class="pre">that</span> <span class="pre">are</span> <span class="pre">present</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">input.</span> <span class="pre">The</span> <span class="pre">output</span>
<span class="pre">will</span> <span class="pre">be</span> <span class="pre">a</span> <span class="pre">new</span> <span class="pre">``TensorMap</span></code> with the same keys as the input, now with the
correct output metadata.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># apply the ModuleMap to the whole tensor map of features</span>
<span class="n">prediction_full</span> <span class="o">=</span> <span class="n">linear_mmap</span><span class="p">(</span><span class="n">feature_tensormap</span><span class="p">)</span>

<span class="c1"># filter the features to only contain one of the blocks,</span>
<span class="c1"># and pass it through the ModuleMap</span>
<span class="n">prediction_subset</span> <span class="o">=</span> <span class="n">linear_mmap</span><span class="p">(</span>
    <span class="n">mts</span><span class="o">.</span><span class="n">filter_blocks</span><span class="p">(</span>
        <span class="n">feature_tensormap</span><span class="p">,</span> <span class="n">Labels</span><span class="p">([</span><span class="s2">&quot;key&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">prediction_full</span><span class="o">.</span><span class="n">keys</span><span class="p">,</span> <span class="n">prediction_full</span><span class="o">.</span><span class="n">blocks</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction_subset</span><span class="o">.</span><span class="n">keys</span><span class="p">,</span> <span class="n">prediction_subset</span><span class="o">.</span><span class="n">blocks</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Labels(
    key
     0
     1
     2
) [TensorBlock
    samples (100): [&#39;sample&#39;]
    components (): []
    properties (1): [&#39;property&#39;]
    gradients: None
, TensorBlock
    samples (100): [&#39;sample&#39;]
    components (): []
    properties (2): [&#39;property&#39;]
    gradients: None
, TensorBlock
    samples (100): [&#39;sample&#39;]
    components (): []
    properties (3): [&#39;property&#39;]
    gradients: None
]
Labels(
    key
     1
) [TensorBlock
    samples (100): [&#39;sample&#39;]
    components (): []
    properties (2): [&#39;property&#39;]
    gradients: None
]
</pre></div>
</div>
<p>Now we define a loss function and run a training loop. This is the same as in
the previous tutorials.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># define a custom loss function for TensorMaps that computes the squared error and</span>
<span class="c1"># reduces by a summation operation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TensorMapLoss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A custom loss function for TensorMaps that computes the squared error and reduces by</span>
<span class="sd">    sum.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_input</span><span class="p">:</span> <span class="n">TensorMap</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">TensorMap</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the total squared error between the ``_input`` and ``target``</span>
<span class="sd">        TensorMaps.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># inputs and targets should have the same metadata over all axes</span>
        <span class="k">assert</span> <span class="n">mts</span><span class="o">.</span><span class="n">equal_metadata</span><span class="p">(</span><span class="n">_input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="n">squared_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">_input</span><span class="o">.</span><span class="n">keys</span><span class="p">:</span>
            <span class="n">squared_loss</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">_input</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">target</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">squared_loss</span>


<span class="c1"># construct a basic training loop. For brevity we will not use datasets or dataloaders.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">training_loop</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loss_fn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">features</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">TensorMap</span><span class="p">],</span>
    <span class="n">targets</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">TensorMap</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A basic training loop for a model and loss function.&quot;&quot;&quot;</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">501</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ScriptObject</span><span class="p">):</span>
            <span class="c1"># assume a TensorMap and check metadata is equivalent</span>
            <span class="k">assert</span> <span class="n">mts</span><span class="o">.</span><span class="n">equal_metadata</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="n">loss_fn_mts</span> <span class="o">=</span> <span class="n">TensorMapLoss</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;with NN = [Linear]&quot;</span><span class="p">)</span>
<span class="n">training_loop</span><span class="p">(</span><span class="n">linear_mmap</span><span class="p">,</span> <span class="n">loss_fn_mts</span><span class="p">,</span> <span class="n">feature_tensormap</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>with NN = [Linear]
epoch: 0, loss: 769.1011737074874
epoch: 100, loss: 152.43308577101345
epoch: 200, loss: 95.21448836273512
epoch: 300, loss: 74.85845598989255
epoch: 400, loss: 64.58524404959572
epoch: 500, loss: 58.463045951762794
</pre></div>
</div>
</section>
<section id="more-complex-architectures">
<h2>More complex architectures<a class="headerlink" href="#more-complex-architectures" title="Link to this heading">¶</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defining more complicated architectures is a matter of building</span>
<span class="c1"># ``torch.nn.Sequential`` objects for each block, and wrapping them into a single</span>
<span class="c1"># ModuleMap.</span>

<span class="n">hidden_layer_width</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">modules</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">:</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span><span class="p">)),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span><span class="p">),</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">hidden_layer_width</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">hidden_layer_width</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">target_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span><span class="p">),</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

<span class="c1"># initialize the ModuleMap as in the previous section.</span>
<span class="n">custom_mmap</span> <span class="o">=</span> <span class="n">ModuleMap</span><span class="p">(</span>
    <span class="n">in_keys</span><span class="p">,</span>
    <span class="n">modules</span><span class="p">,</span>
    <span class="n">out_properties</span><span class="o">=</span><span class="p">[</span><span class="n">target_tensormap</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">properties</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">in_keys</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">custom_mmap</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;with NN = [LayerNorm, Linear, ReLU, Linear, Tanh]&quot;</span><span class="p">)</span>
<span class="n">training_loop</span><span class="p">(</span><span class="n">custom_mmap</span><span class="p">,</span> <span class="n">loss_fn_mts</span><span class="p">,</span> <span class="n">feature_tensormap</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ModuleMap(
  (0): Sequential(
    (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=64, out_features=32, bias=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=1, bias=True)
    (4): Tanh()
  )
  (1): Sequential(
    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=128, out_features=32, bias=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=2, bias=True)
    (4): Tanh()
  )
  (2): Sequential(
    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=256, out_features=32, bias=True)
    (2): ReLU()
    (3): Linear(in_features=32, out_features=3, bias=True)
    (4): Tanh()
  )
)
with NN = [LayerNorm, Linear, ReLU, Linear, Tanh]
epoch: 0, loss: 628.4115434117372
epoch: 100, loss: 102.15331090664478
epoch: 200, loss: 93.55173279931788
epoch: 300, loss: 92.10713211723296
epoch: 400, loss: 91.57975604835907
epoch: 500, loss: 91.33320804749201
</pre></div>
</div>
<p>ModuleMap objects can also be wrapped in a <code class="docutils literal notranslate"><span class="pre">torch.nn.torch.nn.Module</span></code> to
allow construction of complex architectures. For instance, we can have a
“ResNet”-style neural network module that takes a ModuleMap and applies it,
then sums with some residual connections. Wikipedia has a good summary and
diagram of this architectural motif, see:
<a class="reference external" href="https://en.wikipedia.org/wiki/Residual_neural_network">https://en.wikipedia.org/wiki/Residual_neural_network</a> .</p>
<p>To do the latter step, we can combine application of the <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code> with a
<code class="docutils literal notranslate"><span class="pre">Linear</span></code> convenience layer from metatensor-learn, and the sparse addition operation
from <code class="docutils literal notranslate"><span class="pre">metatensor-operations</span></code> to build a complex architecture.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ResidualNetwork</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_keys</span><span class="p">:</span> <span class="n">Labels</span><span class="p">,</span>
        <span class="n">in_features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">out_properties</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Labels</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Build the module map as before</span>
        <span class="n">hidden_layer_width</span> <span class="o">=</span> <span class="mi">32</span>
        <span class="n">modules</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">in_feats</span><span class="p">,</span> <span class="n">out_props</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_properties</span><span class="p">):</span>
            <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">in_feats</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
                    <span class="n">in_features</span><span class="o">=</span><span class="n">in_feats</span><span class="p">,</span>
                    <span class="n">out_features</span><span class="o">=</span><span class="n">hidden_layer_width</span><span class="p">,</span>
                    <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
                    <span class="n">in_features</span><span class="o">=</span><span class="n">hidden_layer_width</span><span class="p">,</span>
                    <span class="n">out_features</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">out_props</span><span class="p">),</span>
                    <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
            <span class="p">)</span>
            <span class="n">modules</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">module_map</span> <span class="o">=</span> <span class="n">ModuleMap</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="p">,</span>
            <span class="n">modules</span><span class="p">,</span>
            <span class="n">out_properties</span><span class="o">=</span><span class="n">out_properties</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># build the input projection layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span>
            <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
            <span class="n">out_properties</span><span class="o">=</span><span class="n">out_properties</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">TensorMap</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorMap</span><span class="p">:</span>
        <span class="c1"># apply the module map to the features</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_map</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># apply the projection layer to the features</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># add the prediction and residual together using the sparse addition</span>
        <span class="c1"># from metatensor-operations</span>
        <span class="k">return</span> <span class="n">mts</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">residual</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">ResidualNetwork</span><span class="p">(</span>
    <span class="n">in_keys</span><span class="o">=</span><span class="n">in_keys</span><span class="p">,</span>
    <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
    <span class="n">out_properties</span><span class="o">=</span><span class="p">[</span><span class="n">block</span><span class="o">.</span><span class="n">properties</span> <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="n">target_tensormap</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;with NN = [LayerNorm, Linear, ReLU, Linear, Tanh] plus residual connections&quot;</span><span class="p">)</span>
<span class="n">training_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_fn_mts</span><span class="p">,</span> <span class="n">feature_tensormap</span><span class="p">,</span> <span class="n">target_tensormap</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>with NN = [LayerNorm, Linear, ReLU, Linear, Tanh] plus residual connections
epoch: 0, loss: 877.4945870891794
epoch: 100, loss: 18.696672961002434
epoch: 200, loss: 3.845163971248074
epoch: 300, loss: 1.5772835196534585
epoch: 400, loss: 0.8379008238832794
epoch: 500, loss: 0.46250230046218666
</pre></div>
</div>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">¶</a></h2>
<p>In this tutorial we have seen how to build custom architectures using <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code>.
This allows for arbitrary architectures to be built, as long as the metadata is
preserved. We have also seen how to build a custom module that wraps a <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code>
and adds residual connections.</p>
<p>The key takeaway is that <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code> can be used to wrap any combination of native
<code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> modules to make them compatible with <code class="docutils literal notranslate"><span class="pre">TensorMap</span></code>. In combination with
convenience layers seen in the tutorial <a class="reference internal" href="3-nn-modules-basic.html#learn-tutorial-nn-modules-basic"><span class="std std-ref">nn modules basic</span></a>, and sparse-data operations from
<code class="docutils literal notranslate"><span class="pre">metatensor-operations</span></code>, complex architectures can be built with ease.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 6.560 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-learn-5-nn-using-modulemap-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/93d616b157ab05ef6448e591b119c185/5-nn-using-modulemap.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">5-nn-using-modulemap.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/406eb0a49111421da7722cd329f019bb/5-nn-using-modulemap.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">5-nn-using-modulemap.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8ef00ad7327ccca0fe2dccaf571f8353/5-nn-using-modulemap.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">5-nn-using-modulemap.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../../learn/CHANGELOG.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Changelog</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="4-nn-modules-equivariant.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Equivariance-preserving <code class="docutils literal notranslate"><span class="pre">nn</span></code> modules</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, the metatensor developers
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Custom architectures with <code class="docutils literal notranslate"><span class="pre">ModuleMap</span></code></a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#starting-simple">Starting simple</a></li>
<li><a class="reference internal" href="#more-complex-architectures">More complex architectures</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=46bd48cc"></script>
    <script src="../../_static/toggleprompt.js?v=5801b3bb"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../_static/js/custom.js?v=4b1677b9"></script>
    <script data-domain="docs.metatensor.org" defer="defer" src="https://plausible.io/js/script.js"></script>
    </body>
</html>